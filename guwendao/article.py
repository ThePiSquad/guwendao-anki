"""Details of a single article"""

import re
import requests
import bs4
from bs4 import BeautifulSoup
from loguru import logger

from .error import UsageError


class Article:
    """Representing a single article"""

    url: str

    title: str
    author: str
    content: str

    content_translation: list[str]
    word_explanation: list[tuple[str, str]]

    translation_id: int
    appreciation_id: int
    idjm_string: str  # some identifier used for verification

    @property
    def is_loaded(self):
        return len(self.content_translation) > 0 and len(self.word_explanation) > 0

    @staticmethod
    def _get_translation_id(soup: BeautifulSoup) -> int:
        """Get the translation id for current article
        Guwendao uses this id to fetch detailed content
        """
        try:
            return int(
                soup.select_one('[id^="fanyiquan"]').get("id").replace("fanyiquan", "")
            )
        except AttributeError:
            return -1

    @staticmethod
    def _get_appreciation_id(soup: BeautifulSoup) -> int:
        try:
            return int(
                soup.select_one('[id^="shangxiquan"]')
                .get("id")
                .replace("shangxiquan", "")
            )
        except AttributeError:
            return -1

    @staticmethod
    def _get_idjm_string(soup: BeautifulSoup) -> str:
        href = soup.find_all("a", href=re.compile(r"^javascript:shangxiShow"))[0].get(
            "href"
        )
        match = re.search(r"shangxiShow\(\d+,'([A-Z0-9]{16})'\)", href)
        if match:
            return match.group(1)
        else:
            raise ValueError(href)

    def __init__(self, url):
        self.url = url
        self.content_translation = list()
        self.word_explanation = list()
        self.load()
        logger.info(
            f""""parsing result:
title: {self.title}
author: {self.author}
translation_id:{self.translation_id}
appreciation_id:{self.appreciation_id}
idjm_string:{self.idjm_string}
content:\n{self.content}
content_translation:\n{self.content_translation}
world_translation:\n{self.word_explanation}"""
        )

    def get_world_explanations(self) -> list["WordExplanation"]:
        """Generate a list of word explanations from this article"""
        return WordExplanation.generate_from_article(self)

    def load(self):
        """Load this article from internet"""
        logger.info(f"fetching article {self.url}")
        response = requests.get(self.url, timeout=1000)
        if response.status_code != 200:
            raise ConnectionRefusedError()

        logger.info("parsing content")
        soup = BeautifulSoup(response.text, "lxml")

        content_block = soup.h1.parent
        self.title = content_block.select_one("h1").text.strip()
        self.author = content_block.select_one("p").text.strip()
        self.content = (
            content_block.select_one(".contson").text.replace(" ", "").strip()
        )

        self.translation_id = self._get_translation_id(soup)
        self.appreciation_id = self._get_appreciation_id(soup)
        self.idjm_string = self._get_idjm_string(soup)

        if self.translation_id == -1:
            self._parse_translation(soup.select_one("div.contyishang"))
        else:
            self._load_translation()

    def _load_translation(self):
        # https://www.gushiwen.cn/nocdn/ajaxfanyi.aspx?id=57185&idjm=9551045DD9900B21
        logger.info("loading translation...")
        response = requests.get(
            f"https://www.gushiwen.cn/nocdn/ajaxfanyi.aspx?id={self.translation_id}&idjm={self.idjm_string}",
            timeout=1000,
        )
        if response.status_code != 200:
            raise ConnectionRefusedError()
        logger.info("parsing translation data")
        soup = BeautifulSoup(response.text, "lxml")

        self._parse_translation(soup.select_one(".contyishang"))

    def _parse_translation(self, tag: bs4.Tag):
        children = tag.select("p")

        content_translation = children[0:-1]
        word_translation = children[-1]

        for element in content_translation:
            text: str = element.text
            if (len(text) == 2 and text.startswith("译文")) or len(text) == 0:
                continue
            self.content_translation.append(text)

        self.word_explanation = _parse_world_translation(word_translation)


def _parse_world_translation(tag: bs4.Tag) -> list[tuple[str, str]]:
    """Partially generated by AI(Grok)"""
    lines = []
    current = []

    # Traverse every direct child of <p>
    for elem in tag.children:
        if elem.name == "br":
            # Finish current line when hitting <br>
            if current:
                text = "".join(str(x) for x in current).strip()
                clean = BeautifulSoup(text, "lxml").get_text().replace("▲", "")
                print(f"{clean:}")
                if clean and clean != "注释":
                    if clean.startswith("注释"):
                        lines.append(clean.removeprefix("注释"))
                    else:
                        lines.append(clean)
                current = []
        else:
            # Accumulate everything else (text, <strong>, <a>, etc.)
            current.append(elem)

    # Critical: capture the last segment (after final <br> or at the very end)
    if current:
        text = "".join(str(x) for x in current).strip().replace("▲", "")
        clean = BeautifulSoup(text, "lxml").get_text()
        if clean:
            lines.append(clean)
    return [tuple(text.split("：", maxsplit=1)) for text in lines]


class WordExplanation:
    """Word translation with context"""

    @staticmethod
    def generate_from_article(article: Article) -> list["WordExplanation"]:
        """Generate a list of WordExplanation objects from a loaded article"""
        if not article.is_loaded:
            raise UsageError()

        result: list[WordExplanation] = list()
        sentences = (
            article.content.replace("，", "。")
            .replace("？", "。")
            .replace("！", "。")
            .split("。")
        )
        for word in article.word_explanation:
            # Search in a single sentence
            # Since the words may not be in order, we have to do a full scan
            for i, s in enumerate(sentences):
                match s.find(re.sub(r"（.+）", lambda m: "", word[0])):
                    case -1:
                        continue
                    case j:
                        result.append(WordExplanation(s, j, word[0], word[1]))
                        break
        return result

    sentence: str
    word: str
    explanation: str
    start: int

    def __init__(self, sentence: str, start: int, word: str, explanation: str):
        self.sentence = sentence
        self.start = start
        self.word = word
        self.explanation = explanation

    def __str__(self):
        return f"{self.sentence},{self.start},{self.word},{self.explanation}"
